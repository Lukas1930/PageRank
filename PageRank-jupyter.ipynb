{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthors:\\n - Nikolaj Thorsen, nivt@itu.dk\\n - Lukas Ditlevsen, lukd@itu.dk\\n - Jonas Hansen, jonha@itu.dk\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Authors:\n",
    " - Nikolaj Thorsen, nivt@itu.dk\n",
    " - Lukas Ditlevsen, lukd@itu.dk\n",
    " - Jonas Hansen, jonha@itu.dk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM SURFER\n",
    "def file_open(filename):\n",
    "    fh=open(filename, 'rb')\n",
    "    G=nx.read_adjlist(fh, create_using=nx.DiGraph())\n",
    "    fh.close()\n",
    "    return G\n",
    "    \n",
    "FILENAMES = ['bigRandom.txt','medium.txt','p2p-Gnutella08-mod.txt','three.txt','tiny.txt','wikipedia.txt'] \n",
    "# NEW: variable that stores the filenames (remember to merge)\n",
    "\n",
    "\n",
    "G=file_open(FILENAMES[2]) \n",
    "\n",
    "\n",
    "def surfer(m,n):\n",
    "    nodeV = [0 for i in range(len(list(G)))]\n",
    "    \n",
    "    # Define starting point for the random surfer simulation\n",
    "    x_current = random.choices(sorted([int(nodes) for nodes in G.nodes()]))\n",
    "    \n",
    "    #initiate for loop that runs n iterations\n",
    "    for e in range(n):\n",
    "\n",
    "        #initiate if statement that changes it's current position to a random node in the net, should a random value\n",
    "        # fall equal to or below the given damping factor, or the current node is a dangeling node \n",
    "        if random.random() <= m or bool(list(G.neighbors(str(x_current[0])))) == False:\n",
    "\n",
    "            # list that holds nodes sorted by their number\n",
    "            g = sorted([int(nodes) for nodes in G.nodes()])\n",
    "\n",
    "            # remove the current node, so as to make sure that, when changing nodes, the new starting point is not the same\n",
    "            # node from which the change was initiated\n",
    "            g.pop(x_current[0])\n",
    "\n",
    "            # change to a random node\n",
    "            x_current = random.choices(g)\n",
    "            nodeV[x_current[0]:x_current[0]+1] = [nodeV[x_current[0]]+1]\n",
    "        \n",
    "        # initiate else-statement that, in the case the simulation did not change to a random node, kept the simulation going\n",
    "        else:\n",
    "            x_current = [int(random.choices(list(G.neighbors(str(x_current[0]))))[0])]\n",
    "            nodeV[x_current[0]:x_current[0]+1] = [nodeV[x_current[0]]+1]\n",
    "    \n",
    "    # return a sorted list of the nodes most visited during the simulation\n",
    "    return sorted(range(len(nodeV)), key=lambda i: nodeV[i])[-10:][::-1]\n",
    "\n",
    "x = surfer(0.15,100000)\n",
    "print(x)\n",
    "\n",
    "# in order from least to most popular, how to reverse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'367': 0.0023876508300157556,\n",
       "  '249': 0.0021842951424048823,\n",
       "  '145': 0.00205488593932474,\n",
       "  '264': 0.0019987499161941607,\n",
       "  '266': 0.0019634403057468244,\n",
       "  '123': 0.0018634931279900295,\n",
       "  '127': 0.001860511078967605,\n",
       "  '122': 0.001853246070158606,\n",
       "  '1317': 0.0018435046570815905,\n",
       "  '5': 0.0018310738884673387},\n",
       " 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def PageRank(G,m,n,t=0.00000001):\n",
    "        # Creating the A matrix by converting the netgraph of G to a numpy array\n",
    "        A = nx.to_numpy_array(G)\n",
    "\n",
    "        # Locates and changes all rows representing dangling nodes to boolean value\n",
    "        degree=np.sum(A,axis=1,keepdims=True)\n",
    "        A=A+(degree==0)\n",
    "\n",
    "        # Normalizes nodes with outgoing edges, so that each entry becomes one divided by the nummber outgoing edges\n",
    "        degree=np.sum(A,axis=1, keepdims=True)\n",
    "        A=A/degree\n",
    "\n",
    "        # Transposing A to make A coloumn-stochastic instead of row-stochastic\n",
    "        A = A.T\n",
    "\n",
    "        # Making the S matrix the dimensions of which is n by n, where n is the number of nodes in the graph\n",
    "        S = np.zeros([len(G),len(G)])\n",
    "\n",
    "        # We fill the S matrix with 1 divided by n in all entries\n",
    "        S.fill(1/len(G))\n",
    "\n",
    "        # Making M matrix\n",
    "        M = (1-m)*A+m*S\n",
    "\n",
    "        # Making X matrix, i.e. x0 - the initial pagerank for all pages, where each page is of equal importance\n",
    "        X = np.zeros([len(G),1])\n",
    "        X.fill(1/len(G))\n",
    "\n",
    "        # Calculating M@X n times, where we expect to get a better and better result for each iteration, until it eventually converges\n",
    "        for i in range(n):\n",
    "            x_1 = M@X\n",
    "            d = np.abs(X-x_1)\n",
    "            if np.mean(d) < t:\n",
    "                return i, X\n",
    "            X = x_1\n",
    "        return i, X\n",
    "\n",
    "\n",
    "\n",
    "# we store the output of the pagerank function in a variable x, which outputs to be a column array of dimensions len(G) by 1\n",
    "iterations, x = PageRank(G,0.15,100)\n",
    "\n",
    "#\n",
    "d = dict(zip(G.nodes(), x.flatten()))\n",
    "\n",
    "# Sort d in terms of the values of the keys - return dict with the ten most popular pages\n",
    "dic=dict((Counter(d)).most_common(10))\n",
    "dic, iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.sparse' has no attribute 'coo_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\ITU\\1 semester\\introduction to programming\\PageRankExampleData\\PageRank-jupyter.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ITU/1%20semester/introduction%20to%20programming/PageRankExampleData/PageRank-jupyter.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m l \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mpagerank(G,alpha\u001b[39m=\u001b[39;49m\u001b[39m0.85\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ITU/1%20semester/introduction%20to%20programming/PageRankExampleData/PageRank-jupyter.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdict\u001b[39m((Counter(l))\u001b[39m.\u001b[39mmost_common(\u001b[39m10\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\luka1\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:108\u001b[0m, in \u001b[0;36mpagerank\u001b[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpagerank\u001b[39m(\n\u001b[0;32m     10\u001b[0m     G,\n\u001b[0;32m     11\u001b[0m     alpha\u001b[39m=\u001b[39m\u001b[39m0.85\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     dangling\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     18\u001b[0m ):\n\u001b[0;32m     19\u001b[0m     \u001b[39m\"\"\"Returns the PageRank of the nodes in the graph.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[39m    PageRank computes a ranking of the nodes in the graph G based on\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[39mreturn\u001b[39;00m pagerank_scipy(\n\u001b[0;32m    109\u001b[0m         G, alpha, personalization, max_iter, tol, nstart, weight, dangling\n\u001b[0;32m    110\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\luka1\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:469\u001b[0m, in \u001b[0;36mpagerank_scipy\u001b[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[39mreturn\u001b[39;00m {}\n\u001b[0;32m    468\u001b[0m nodelist \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(G)\n\u001b[1;32m--> 469\u001b[0m A \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mto_scipy_sparse_array(G, nodelist\u001b[39m=\u001b[39;49mnodelist, weight\u001b[39m=\u001b[39;49mweight, dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m)\n\u001b[0;32m    470\u001b[0m S \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    471\u001b[0m S[S \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m S[S \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\luka1\\anaconda3\\lib\\site-packages\\networkx\\convert_matrix.py:907\u001b[0m, in \u001b[0;36mto_scipy_sparse_array\u001b[1;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[0;32m    904\u001b[0m     row, col, data \u001b[39m=\u001b[39m [], [], []\n\u001b[0;32m    906\u001b[0m \u001b[39mif\u001b[39;00m G\u001b[39m.\u001b[39mis_directed():\n\u001b[1;32m--> 907\u001b[0m     A \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mcoo_array((data, (row, col)), shape\u001b[39m=\u001b[39m(nlen, nlen), dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    908\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    909\u001b[0m     \u001b[39m# symmetrize matrix\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     d \u001b[39m=\u001b[39m data \u001b[39m+\u001b[39m data\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.sparse' has no attribute 'coo_array'"
     ]
    }
   ],
   "source": [
    "l = nx.pagerank(G,alpha=0.85)\n",
    "dict((Counter(l)).most_common(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c5b71dd20748231afc8bc5b937a6902b0a59018d7248bc9b6ad7cc239611026"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
